<!DOCTYPE html>
<html>

<head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PR5ZWQKH');</script>
    <!-- End Google Tag Manager -->
    <title>VIBeID</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="./css/style.css" />
    <link href="./css/font-awesome.css" rel="stylesheet" type="text/css"> 
</head>

<body class="light">
    <div id="header">
        <a class="header-title" href="./">VIBeID</a>
        <div class="header-links">
            <a class="header-link" href="#abstract">Abstract</a>
            <a class="header-link" href="#dataset">Dataset</a>
            <a class="header-link" href="#rooms">Setup Locations</a>
            <a class="header-link" href="#tasks">Use Cases</a>
            <!-- <a class="header-link" href="#bibtex">BIBTEX</a> -->
        </div>
        <div id="color-mode-wrap">
            <div id="color-light" class="color-mode">
                <i class="color-mode-icon fa-regular fa-sun"></i>
                <span>Light</span>
            </div>
            <div id="color-dark" class="color-mode">
                <i class="color-mode-icon fa-regular fa-moon"></i>
                <span>Dark</span>
            </div>
        </div>
    </div>
    <div class="container">
        <h1>VIBeID: A Structural Vibration-based Soft Biometric Dataset and Benchmark for Person Identification</h1>
        <h3>Under Review</h3>
        <div class="authors">
            <div class="author">
                <div class="author-name">
                    <a href="https://mainakchakraborty.com/">Mainak Chakraborty</a>
                </div>
                <div class="author-uni">IIT, Delhi</div>
            </div>
            <div class="author">
                <div class="author-name">
                    <a href="https://web.iitd.ac.in/~eez218527">Chandan</a>
                </div>
                <div class="author-uni">IIT, Delhi</div>
            </div>
            <div class="author">
                <div class="author-name">
                    <a href="https://cemse.kaust.edu.sa/ece/people/person/bodhibrata-mukhopadhyay">Bodhibrata Mukhopadhyay</a>
                </div>
                <div class="author-uni">IIT, Roorkee</div>
            </div>
            
        </div>
        <div class="authors">
            
            <div class="author">
                <div class="author-name">
                    <a href="https://sites.google.com/view/sahilanchal/home">Sahil Anchal</a>
                </div>
                <div class="author-uni">IIT, Delhi</div>
            </div>
            <div class="author">
                <div class="author-name">
                    <a href="https://web.iitd.ac.in/~subrat/">Subrat Kar</a>
                </div>
                <div class="author-uni">IIT, Delhi</div>
            </div>
        </div>
        <div class="links">
            <div class="link">
                <a href="#home" target="_blank" rel="noopener noreferrer">
                <img src="./images/file-solid.svg" alt="Paper" width="30" height="30" />
                <div class="link-text">Paper</div>
                </a>
            </div>
            <div class="link">
                <a href="https://osf.io/4fvnj/">
                <img src="./images/database-solid.svg" alt="Dataset in OSF*" width="30" height="30" />
                <div class="link-text">Dataset OSF</div>
                </a>
            </div>
             <div class="link">
                <a href="https://csciitd-my.sharepoint.com/:f:/g/personal/eez218527_iitd_ac_in/Eio2kmjTholNh2uxhV5RZZABD2cOOgfy5jIiPZIb50fEtw?e=MEBfxp">
                <img src="./images/database-solid.svg" alt="Dataset in onedrive" width="30" height="30" />
                <div class="link-text">Dataset Onedrive</div>
                </a>
            </div>
            <div class="link">
                <a href="https://github.com/VIBeID/VIBEID" target="_blank" rel="noopener noreferrer">
                <img src="./images/github.svg" alt="Code" width="30" height="30" />
                <div class="link-text">Code</div>
                </a>
            </div>
            <!-- <div class="link">
                <a href="RealImpact_appendix.pdf" target="_blank" rel="noopener noreferrer">
                <i class="link-icon fa-solid fa-file-lines"></i>
                <div class="link-text">appendix</div>
                </a>
            </div> -->
        </div>
        *If the OSF is down, directly download from Onedrive
        <div class="section" id="abstract">
            <h2 class="section-title">Abstract</h2>
            <p class="abstract-text">
                We present VIBeID, a dataset and benchmark designed for advancing non-invasive person identification through structural vibration. Structural vibrations, produced by the rhythmic impact of the toe and heel on the ground, are distinct and can be used as a privacy-preserving and non-cooperative soft-biometric modality. 
                We curated the largest dataset VIBeID consists of footfall generated structural vibrations of 100 subjects. Existing datasets in this field typically include around ten subjects and lack comprehensive exploration of domain adaptation. To thoroughly explore the domain adaptation aspect of this biometric approach, we recorded vibration data on three distinct floor types (wooden, carpet, and cement) and at three distances from the geophone sensor (1.5 m, 2.5 m, and 4.0 m), involving 40 and 30 subjects, respectively. Additionally, we benchmarked our dataset against video recordings from 15 individuals in an outdoor setting. 
                Beyond providing 88.66 hours of raw vibration data, VIBeID establishes a comprehensive benchmark for a) person identification: where the aim is to recognize individuals through their unique structural vibrations, b) domain adaptation: assessing model performance across different walking surfaces and sensor positions, and c) multi-modal comparison: comparing vibration-based and vision-based identification methods. 
                Our experiments, using both machine learning and deep learning approaches, establish a baseline for future research in this field.

            </p>
        </div>
           <div class="section" id="dataset">
            <h2 class="section-title">Raw Dataset</h2>
            <p class="abstract-text">
                The dataset is hosted on OSF:
                <a href="https://osf.io/4fvnj/" target="_blank" rel="noopener noreferrer">Dataset OSF</a>
            </p>
                <p class="abstract-text">
                The dataset is hosted on Onedrive:
                <a href="https://csciitd-my.sharepoint.com/:f:/g/personal/eez218527_iitd_ac_in/Eio2kmjTholNh2uxhV5RZZABD2cOOgfy5jIiPZIb50fEtw?e=MEBfxp" target="_blank" rel="noopener noreferrer">Dataset Onedrive</a>
                <p class="abstract-text"></p>
                <div class="section" id="datasets">
                  <h2 class="section-title">Pre-Processed Dataset Links</h2>
                  <div class="datasets-image-container" style="display: flex; flex-wrap: wrap; gap: 20px;">
                    <div class="image-wrapper" style="text-align: center; flex: 1;">
                      <h3>VIBeID A1</h3>
                      <img src="./images/100_people.png" alt="VIBeID A1" style="width: 150px; height: 150px;" />
                      <div class="dataset-links">
                        <a href="https://www.kaggle.com/code/mainakml/vibeida1"><i class="fas fa-code"></i> VIBeID A1 Code</a>
                        <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a1">
                          <img src="https://www.kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle" style="width: 120px; height: auto;" />
                        </a>
                      </div>
                    </div>
                    <div class="image-wrapper" style="text-align: center; flex: 1;">
                      <h3>VIBeID A2</h3>
                      <img src="./images/three_distances.png" alt="VIBeID A2" style="width: 150px; height: 150px;" />
                      <div class="dataset-links">
                        <a href="https://www.kaggle.com/code/mainakml/vibeida2"><i class="fas fa-code"></i> VIBeID A2 Code</a>
                        <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a2">
                          <img src="https://www.kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle" style="width: 120px; height: auto;" />
                        </a>
                      </div>
                    </div>
                    <div class="image-wrapper" style="text-align: center; flex: 1;">
                      <h3>VIBeID A3</h3>
                      <img src="./images/three_floor.png" alt="VIBeID A3" style="width: 150px; height: 150px;" />
                      <div class="dataset-links">
                        <a href="https://www.kaggle.com/code/mainakml/vibeida3"><i class="fas fa-code"></i> VIBeID A3 Code</a>
                        <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a3">
                          <img src="https://www.kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle" style="width: 120px; height: auto;" />
                        </a>
                      </div>
                    </div>
                    <div class="image-wrapper" style="text-align: center; flex: 1;">
                      <h3>VIBeID A4.1</h3>
                      <img src="./images/a4.png" alt="VIBeID A4.1" style="width: 150px; height: 150px;" />
                      <div class="dataset-links">
                        <a href="https://www.kaggle.com/code/mainakml/vibeida41"><i class="fas fa-code"></i> VIBeID A4.1 Code</a>
                        <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a-4-1">
                          <img src="https://www.kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle" style="width: 120px; height: auto;" />
                        </a>
                      </div>
                    </div>
                    <div class="image-wrapper" style="text-align: center; flex: 1;">
                      <h3>VIBeID A4.2</h3>
                      <img src="./images/a4.2.png" alt="VIBeID A4.2" style="width: 150px; height: 150px;" />
                      <div class="dataset-links">
                        <a href="https://www.kaggle.com/code/mainakml/vibeida4ab"><i class="fas fa-code"></i> VIBeID A4.2 Code</a>
                        <a href="https://www.kaggle.com/datasets/mainakml/geitttt/data">
                          <img src="https://www.kaggle.com/static/images/open-in-kaggle.svg" alt="Kaggle" style="width: 120px; height: auto;" />
                        </a>
                      </div>
                    </div>
                  </div>
                </div>
                The pre-preprocessed signal dataset is available on kaggle: <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a1-event"><i class="fas fa-database"></i>A1 Signal Data, <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a2-event"><i class="fas fa-database"></i>A2 Signal Data</a><a href="https://www.kaggle.com/datasets/mainakml/vibeid-a3-event"><i class="fas fa-database"></i>A3 Signal Data</a>, and <a href="https://www.kaggle.com/datasets/mainakml/a4-1signal"><i class="fas fa-database"></i>A4.1 Signal Data</a> 
            <p class="abstract-text">
                The compressed archives include raw recordings of vibration and visual data for all the subdatasets used in our experiments.
                Subdatasets are sorted by their use cases.
                <ul>
                    <li>
                        VIBeID A1 subdataset is for Person Identification, it consists of 100 participants, 68 males, and 32 females spanning 20-60 years. Each individual has 20 minutes of recorded data.
                        The pre-preprocessed signal dataset is available on kaggle: <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a1-event"><i class="fas fa-database"></i>A1 Signal Data</a> and code is available of <a href="https://www.kaggle.com/code/mainakml/vibeid-a1-signal"><i class="fas fa-database"></i>Code</a>
                    </li>
                    <li>
                        VIBeID A2 subdataset is for Multi-Distance analysis, it consists of 30 participants, 16 males, and 14 females. Each individual has 15 minutes of recorded data for each distances (1.5m, 2.5m and 4.0m).
                        The pre-preprocessed signal dataset is available on kaggle: <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a2-event"><i class="fas fa-database"></i>A2 Signal Data</a> and code is available of <a href="https://www.kaggle.com/code/mainakml/vibeid-a2-signal"><i class="fas fa-database"></i>Code</a>
                    </li>
                    <li>
                        VIBeID A3 subdataset is for Multi-Structure analysis, it consists of 40 participants, 23 males, and 17 females. Each individual has 15 minutes of recorded for each floor type (wooden, carpet, and cement).
                        The pre-preprocessed signal dataset is available on kaggle: <a href="https://www.kaggle.com/datasets/mainakml/vibeid-a3-event"><i class="fas fa-database"></i>A3 Signal Data</a> and code is available of <a href="https://www.kaggle.com/code/mainakml/vibeid-a3-signal"><i class="fas fa-database"></i>Code</a>
                    </li>
                    <li>
                        VIBeID A4 subdataset is for Multi-Modal analysis, it consists of 15 participants, 9 males, and 6 females. VIBeID A4 subdataset consists of 2 modalities, 1 vibration and 1 vision. VIBeID A4.1 consists of vibration data of 10 minutes for each participants, whereas VIBeID A4.2a, and A4.2b are 2 vision based data of 10 minutes for each participants.
                        The pre-preprocessed signal dataset is available on kaggle: <a href="https://www.kaggle.com/datasets/mainakml/a4-1signal"><i class="fas fa-database"></i>A4.1 Signal Data</a> and code is available of <a href="https://www.kaggle.com/code/mainakml/vibea41signal"><i class="fas fa-database"></i>Code</a>
                    </li>
                </ul>
            <div class="preprocessed-list">

            <!-- <h3>Sample Dataset</h3>
            <p class="abstract-text">  
                We provide a small downloadable sample dataset: <a href="#home" target="_blank" rel="noopener noreferrer">Download small_sampledataset</a>
                The files are VIBeID A1 dataset, preprocessed, but the number of persons and data points has been significantly reduced. Information on the data's organization is included below.
            </p> -->
              <div class="section" id="rooms">
            <h2 class="section-title">Setup Locations</h2>
            <div class="rooms-image-container">
                <div class="image-wrapper">
                    <h3>Wooden Floor</h3>
                    <img src="./images/Wooden_left_view.jpg" alt="VIBeID A3.1" />
                </div>
                <div class="image-wrapper">
                    <h3>Carpet Floor</h3>
                    <img src="./images/carpet_test.jpg" alt="VIBeID A3.2" />
                </div>
                <div class="image-wrapper">
                    <h3>Cement Floor</h3>
                    <img src="./images/Cement_2.jpg" alt="VIBeID A3.3" />
                </div>
                <div class="image-wrapper">
                    <h3>Outdoor Ground</h3>
                    <img src="./images/aout.png" alt="VIBeID A4.1" />
                </div>
            </div>

            <div class="rooms-text" display="flex">

                <ul>
                    <li>
                        <b>Wooden Floor</b> represents VIBeID A3.1 dataset location, 
                        where 30 individuals consists of 23 Males, 17 Females walks for 15 minutes at a distance of around 2.5m - 4.0m from a geophone sensor. </li>
                    <li>
                        <b>Carpet Floor</b> represents VIBeID A3.2 dataset location, 
                        where all the same individuals who walked for VIBeID A3.1 were asked to walk for 15 minutes.
                    </li>
                    <li>
                        <b>Cement Floor</b> represents VIBeID A3.3 dataset location, 
                        where all the same individuals who walked for VIBeID A3.1 were asked to walk for 15 minutes.
                    </li>
                    <li>
                        <b>Outdoor</b> represents VIBeID A4.1 and VIBeID 4.2 dataset location, 
                        where 15 individuals consists of 9 Males, 6 Females walked for 10 minutes at a distance of around 4.0m from a geophone sensor and cameras.
                    </li>
                </ul>
            </div>
            
            <p class="abstract-text">
                Below, we show Visual depiction of VIBeID A4’s data collection framework showcasing structural vibration signals, and Signal
                envelope (Hilbert Transform) in outdoor scenario.

                <div class="img-container">
                    <div class="image-wrapper-1">
                        <img src="./images/VIBeID_walking.svg" alt="Visual Depiction of VIBeID's data collection Framework" />
                    </div>
                </div>
            </p>
        </div>
        <div class="section" id="tasks">
            <h2 class="section-title">Use Cases</h2>
            <div class="img-container">
                <div class="image-wrapper-1">
                    <img src="./images/VIBeID_usage_image.png" alt="Visual Depiction of VIBeID's data Applications" />
                </div>
            </div>
            <p class="abstract-text">
                The VIBeID dataset can be used for:
                <ul>
                    <li>
                        <b>Person Identification :</b> can be perfomed using Multi-Class Classification techniques on VIBeID A1 dataset.
                    </li>
                    <li>
                        <b>Multi-Distance :</b> VIBeID A2 dataset can be used to evaluate how performance of model can be influenced when data is recorded at distinct distances.
                    </li>
                    <li>
                        <b>Multi-structure :</b> VIBeID A3 dataset can be used to evaluate how structural properties impact the performance of model in person identification.
                    </li>
                    <li>
                        <b>Multi-Modal Analysis :</b> VIBeID A4 dataset is used for performance comparison of vision-based systems and vibration-based systems.  
                    </li>
                </ul>
            </p>
            <hr>
        </div>
            <h3>Dataset details and preparation</h3>
            <p class="abstract-text"> 
                Our preprocessed data will serve most use cases. To ensure privacy and identity protection, participants are anonymized and referred to by identifiers such as P1, P2, and so on.
                The raw dataset details are listed below :
            </p>
            <h4>VIBeID A1 Details</h4>
            <p class="abstract-text">
                The VIBeID A1 dataset comprises recordings from 100 participants, each of whom walked for 20 minutes. The data was captured using geophones on  wooden floor. Each person completed four sets of 5-minute walks.
                he Figure belows shows the data collection on wooden floor for VIBeID A3.1 of Person 14.
                <div class="img-container">
                    <div class="image-wrapper-1">
                        <img src="./images/wooden_gif_2.gif" alt="VIBeID A1 data collection location" />
                    </div>
                </div>
            </p>
            <p class="abstract-text"> 
                VIBeID  A1 dataset file contains
                <ul>
                    <li>One folder for each human in the dataset</li>
                    <li>Folder names are mentioned as P1, P2, ..., P100</li>
                    <li>Each folder consists of atleast 4 mat files, each worth of 5 minutes of vibration data</li>
                    <li>each File names follows FolderName_FileNumber, like P1_1.mat, P1_2.mat, ...</li>
                </ul>
            </p>
            <hr>
            <h4>
                VIBeID A2 details
            </h4>
            <p class="abstract-text">
                The VIBeID A2 dataset comprises recordings from 30 participants, each of whom walked for 15 minutes at three different distances (1.5 m, 2.5 m, and 4.0 m) from geophone sensors. The data was recorded on cement floor. Each person completed three sets of 5-minute walks.
                The figure below depicts the setup location for collecting the VIBeID A1 dataset.
                <div class="img-container">
                    <div class="image-wrapper-1">
                        <img src="./images/cement_multi_distance.png" alt="VIBeID A3 data collection location" />
                    </div>
                </div>
            </p>
            <p class="abstract-text"> 
                VIBeID A2 dataset file contains
                <ul>
                    <li>3 folder for 3 different distances in the dataset</li>
                    <li>A2_1 represents vibration data recorded at 1.5m far from the geophone sensor</li>
                    <li>A2_1 represents vibration data recorded at 2.5m far from the geophone sensor</li>
                    <li>A2_3 represents vibration data recorded at 4.0m far from the geophone sensor</li>
                    <li>Each folder (A2_1, A2_2, and A2_3) has one folder for each human in the dataset</li>
                    <li>Folder names are mentioned as P1, P2, ..., P30</li>
                    <li>Each folder consists of atleast 3 mat files, each worth of 5 minutes of vibration data</li>
                    <li>Each File names follows FolderName_FileNumber, like P1_1.mat, P1_2.mat, ...</li>    
                </ul>
            </p>
            <hr>
            <h4>
                VIBeID A3 details
            </h4>
            <p class="abstract-text">
                The VIBeID A3 dataset comprises recordings from 40 participants, each of whom walked for 15 minutes at three floors (Wooden, Carpet, Cement) from geophone sensors. Each person completed three sets of 5-minute walks.
            </p>
                <p>The Figure belows shows the different floors used for A3.
                <div class="img-container">
                    <img width="80%" class="gif" src="./images/a3.png">
                </div>
            </p>
            <p class="abstract-text"> 
                VIBeID A3 dataset file contains
                <ul>
                    <li>3 folder for 3 different distances in the dataset</li>
                    <li>A3_1 represents vibration data on Wooden floor</li>
                    <li>A3_2 represents vibration data on Carpet floor</li>
                    <li>A3_3 represents vibration data on Cement floor</li>
                    <li>Each folder (A3_1, A3_2, and A3_3) has one folder for each human in the dataset</li>
                    <li>Folder names are mentioned as P1, P2, ..., P40</li>
                    <li>Each folder consists of atleast 3 mat files, each worth of 5 minutes of vibration data</li>
                    <li>Each File names follows FolderName_FileNumber, like P1_1.mat, P1_2.mat, ...</li>    
                </ul>
            </p>
            <hr>
            <h4>
                VIBeID A4 details 
            </h4>
            </p>
                <p>The Figure belows shows how GEI is calculated for VIBeID A4.2.
                <div class="img-container">
                    <img width="80%" class="gif" src="./images/gei.png">
                </div>
            </p>
            <p class="abstract-text"> 
                VIBeID A4 dataset file contains
                <ul>
                    <li>3 folder 1 for vibration data, 2 for camera data in the dataset</li>
                    <li>A4_1 represents vibration data on Wooden Floor</li>
                    <li>A4_2a represents vision data from Right camera</li>
                    <li>A4_2b represents vision data from Left camera</li>
                    <li>Each folder (A4_1, A4_2a, and A4_2b) has one folder for each human in the dataset</li>
                    <li>Folder names are mentioned as P1, P2, ..., P15</li>
                    <li>In A4_1, each subfolder consists of 1 mat file, each worth of 10 minutes of vibration data</li>
                    <li>Each File names follows FolderName_FileNumber, like P1_1.mat, P1_2.mat, ...</li>
                    <li>In A4_2a, and A4_2b, each subfolder consists of Folder as P1, P2, ..., P15 </li>
                    <li>Each Folder consists of human silhouettes like frame_0,...frame_n</li>
                    <li>Each folder consists of atleast 2000-5000 .png/.jpg files</li>
                </ul>
            </p>
<!--             <h4>Preprocessed Files</h4> -->
<!--             <h4>Preprocessed Files</h4>
            <p class="abstract-text"> 
                Each Subdatasets are preprocessed based on use case scenarios.
                <ul>
                    <li>
                        ----
                    </li>
                    <li>
                        ----
                    </li>
                </ul>
            </p> -->
<!--             <h4>Raw Files</h4>
            <p class="abstract-text"> 
                The raw files are provided. -->
            <hr>
            </p>
            <h3>Maintenance</h3>
            <p class="abstract-text">
                Mainak Chakraborty and Chandan are maintaining the dataset.Mainak Chakraborty can be contacted at <a href = "mailto: Mainak.Chakraborty@iddc.iitd.ac.in">Mainak.Chakraborty@iddc.iitd.ac.in</a>, 
                and Chandan can be contacted at <a href = "mailto: chandan@ee.iitd.ac.in">chandan@ee.iitd.ac.in</a>.
            </p>
            <p class="abstract-text">   
                Please contact us if you notice any errors or have any suggestion with the dataset. To the extent that we notice errors, they will be fixed 
                and the dataset will be updated. Previous versions of the dataset will be maintained below and errors and previous versions will be posted below.
            </p>
        </div>
        <!--
        <div class="section" id="bibtex">
            <h2 class="section-title">BibTex</h2>
            <pre id="citation">@inproceedings{chakraborty2024vibeid,
    title={VIBeID: A Structural Vibration-based Soft Biometric Dataset and Benchmark for Person Identification},
    author={Mainak Chakraborty, Chandan, Sahil Anchal ,Bodhibrata Mukhopadhyay, and Subrat Kar},
    booktitle={Advances in Neural Informaion Processing Systems},
    year={2024}
}</pre>
        </div> -->

    </div>
        <hr>
        <div id="footer">
        <div class="footer-text">This website is created with this <a href="https://masonlwang.com/soundcam/" class="template-creator">template.</a></div>
    </div>

    <script>
        document.getElementById("color-mode-wrap").addEventListener("click", () => {
            document.body.classList.toggle("light");
            document.body.classList.toggle("dark");
        });
    </script>
</body>

</html>
